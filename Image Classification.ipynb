{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57eba448",
   "metadata": {},
   "source": [
    "# Image classification using PyTorch library\n",
    "\n",
    "A simple classification excercise to identify images of cats and dogs using PyTorch ans study it's various functionalities.\n",
    "The dataset is taken from kaggle which is contributed by sachin.\n",
    "There are a total of 12500 images of cats and dogs respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d4eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0d6246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Collecting desciptive stats of image dimensions\n",
    "\n",
    "width = []\n",
    "height = []\n",
    "file = os.listdir('data/cvd/PetImages/cats_and_dogs')\n",
    "folder = r'data\\cvd\\PetImages\\cats_and_dogs'\n",
    "for i in range(len(file)):\n",
    "    image_path = os.path.join(folder,file[i])\n",
    "    img = mpimg.imread(image_path)\n",
    "    width.append(img.shape[0])\n",
    "    height.append(img.shape[1])\n",
    "\n",
    "width_array = np.array(width)\n",
    "height_array = np.array(height)\n",
    "\n",
    "mean_width = np.mean(width_array)\n",
    "mean_height = np.mean(height_array)\n",
    "\n",
    "plt.hist(width_array,20,(50,550))\n",
    "plt.title('Width distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(height_array,20,(50,550))\n",
    "plt.title('Height distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c2fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a custom dataset class that extends from torch.utils.data module\n",
    "class CatsandDogsDataset(Dataset):\n",
    "    def __init__(self,csv_file,root_dir,transform=None):\n",
    "        self.annotation = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotation)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image_path = os.path.join(self.root_dir,self.annotation.iloc[index,0])\n",
    "        #image = io.imread(image_path)\n",
    "        image = Image.open(image_path)\n",
    "        y_label = torch.tensor(int(self.annotation.iloc[index,1]))\n",
    "        #f_name = self.annotation.iloc[index,0]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return (image,y_label)#,f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5821d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A subset of 2990 images are used for training and testing the network\n",
    "dataset = CatsandDogsDataset(\n",
    "    csv_file='/pytorch/data/cvd/PetImages/labels2.csv',\n",
    "    root_dir='/pytorch/data/cvd/PetImages/cats_and_dogs',\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e38a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop to check if all images have R,G,B layers. Some images considered had faulty dimensions.\n",
    "#These were eventually deleted based on names of files displayed by the below loop\n",
    "for image,label,f_name in dataset:\n",
    "  if image.shape[0] != 3:\n",
    "    print(image.shape,label,f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5afe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,val_set = torch.utils.data.random_split(dataset,[2900,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1e888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a loader object from the split dataset.This function wraps an iterable over the dataset object\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=32,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286ce4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing a pretrained Alexnet network which is provided by PyTorch\n",
    "import torchvision.models as models\n",
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eb044f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing parameters of the sequential part called 'features' \n",
    "for params in model.features.parameters():\n",
    "  params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310262d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifying the layers of the classifier part to output only 2 class labels as need for this task\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(9216,4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096,1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c023b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the loss condition and optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b4ead1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 batch:   30 [   960/2900] loss: 0.28822932 | accuracy:  73.646\n",
      "epoch:  0 batch:   60 [  1920/2900] loss: 0.34969041 | accuracy:  82.031\n",
      "epoch:  0 batch:   90 [  2880/2900] loss: 0.24607244 | accuracy:  84.479\n",
      "val --> epoch:  0 | loss: 0.46450332 | accuracy:  79.000\n",
      "epoch:  1 batch:   30 [   960/2900] loss: 0.25332367 | accuracy:  94.896\n",
      "epoch:  1 batch:   60 [  1920/2900] loss: 0.10097232 | accuracy:  94.427\n",
      "epoch:  1 batch:   90 [  2880/2900] loss: 0.20255177 | accuracy:  94.236\n",
      "epoch:  2 batch:   30 [   960/2900] loss: 0.03409335 | accuracy:  97.188\n",
      "epoch:  2 batch:   60 [  1920/2900] loss: 0.30338097 | accuracy:  96.823\n",
      "epoch:  2 batch:   90 [  2880/2900] loss: 0.11988381 | accuracy:  96.354\n",
      "val --> epoch:  2 | loss: 0.34854141 | accuracy:  85.000\n",
      "\n",
      "Duration: 439 seconds\n"
     ]
    }
   ],
   "source": [
    "#Setting up the training and validation loop\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 3\n",
    "train_losses = []\n",
    "train_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    val_corr = 0\n",
    " \n",
    "    for b,(X_train,y_train) in enumerate(train_loader):\n",
    "        b += 1\n",
    "        optimizer.zero_grad()\n",
    "        #X, y = X_train.to(device), y_train.to(device) ---------TO be used when GPU is available\n",
    "        \n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred,y_train)\n",
    "        \n",
    "        predicted = torch.max(y_pred.data,1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if b%30 == 0:\n",
    "            print(f'epoch: {i:2} batch: {b:4} [{32*b:6}/2900] loss: {loss.item():10.8f} | accuracy: {trn_corr.item()*100/(32*b):7.3f}')\n",
    "            \n",
    "        train_losses.append(loss)\n",
    "        train_correct.append(trn_corr)\n",
    "        \n",
    "    if i%2 == 0:\n",
    "        for bat,(X_val,y_val) in enumerate(val_loader):\n",
    "            bat+=1\n",
    "            with torch.no_grad():\n",
    "                y_val_pred = model(X_val)\n",
    "                loss = criterion(y_val_pred,y_val)\n",
    "                    \n",
    "                predicted = torch.max(y_val_pred.data,1)[1]\n",
    "                batch_corr = (predicted == y_val).sum()\n",
    "                val_corr += batch_corr\n",
    "\n",
    "        print(f'val --> epoch: {i:2} | loss: {loss.item():10.8f} | accuracy: {val_corr*100/96:7.3f}')\n",
    "                    \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daa0b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = CatsandDogsDataset(\n",
    "    csv_file='/pytorch/data/cvd/PetImages/test_labels.csv',\n",
    "    root_dir='/pytorch/data/cvd/PetImages/test',\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0ac0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=30,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a26b7c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for b,(x_test,y_test) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "    #X,y = x_test.to(device),y_test.to(device)\n",
    "        y_pred = model(x_test)\n",
    "        predicted = torch.max(y_pred.data,1)[1]\n",
    "        preds.append(predicted)\n",
    "        print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac1dd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corr = 0\n",
    "for i in range(len(y_test)):\n",
    "  if y_test[i].item() == preds[0][i].item():\n",
    "    test_corr+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5370b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89.655\n",
      "Number of correct classifications:  26\n"
     ]
    }
   ],
   "source": [
    "print(f'Test accuracy: {test_corr*100/29:5.3f}')\n",
    "print(f'Number of correct classifications: {test_corr:3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87bb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
